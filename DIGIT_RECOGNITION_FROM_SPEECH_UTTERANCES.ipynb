{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIGIT RECOGNITION FROM SPEECH UTTERANCES",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wVXeOoLU4GH"
      },
      "source": [
        "# <font color='red'> **DIGIT RECOGNITION FROM SPEECH UTTERANCES**\n",
        "#### BY AVI KHANDELWAL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEC450ekUlEF"
      },
      "source": [
        "### Using a set of training and test digit utterances which are present in the folders named “training” and “testing” on the drive, we will be performing digit recognition using K-nearest neighbor (KNN) classifier.\n",
        "The data can be found on this link-\n",
        "https://drive.google.com/drive/folders/1o3cygZjlxfRTkWmV85HbnRYXRCAJU9AB?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN4SUxBIVzeI"
      },
      "source": [
        "#### **1. Importing Libraries-**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1h1bi-5RKCy"
      },
      "source": [
        "import numpy as np\n",
        "from math import sin,cos,pi\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy import stats\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#!pip install python_speech_features\n",
        "from python_speech_features import mfcc\n",
        "from python_speech_features import logfbank\n",
        "import scipy.io.wavfile as wav\n",
        "from python_speech_features import ssc\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "import os, sys\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENQVFBM2cYye"
      },
      "source": [
        "#### **2. Function Definition-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YpO-bjPXNin"
      },
      "source": [
        "# While calculating distance between 2 arrays, 2 norm can be used but to evaluate distance between 2 matrices, a different method has been adopted.\n",
        "# distance between every row of matrix 1 needs to be calculated with every row of matrix 2 and stored as a scalar entry in result matrix.\n",
        "# For instance if we have mat1 with 3 rows and mat2 with 4 rows (arbitrary columns in both matrices), we will have 12 distance values stored in a 3*4 matrix corresponding to every row in mat1 and mat2.\n",
        "# once the result matrix in calculated, we will take an average of all values in the result matrix which will give the final answer as distance between 2 matrices.\n",
        "\n",
        "def dist(arr1,arr2):\n",
        "  rows1 = len(arr1)\n",
        "  rows2 = len(arr2)\n",
        "  mat = np.zeros([rows1,rows2])\n",
        "  for i in range(rows1):\n",
        "    for j in range(rows2):\n",
        "      mat[i][j] = np.linalg.norm(arr1[i]-arr2[j])\n",
        "  return np.sum(mat)/(rows1*rows2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n7qNS3-f058"
      },
      "source": [
        "#### **3. Loading the data-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzAHe5r4ctoD"
      },
      "source": [
        "# Parameter values\n",
        "\n",
        "km = 13 # Value of parameter k in k-means clustering model\n",
        "kn = 13 \n",
        "tr = 300 # Number of training files (.wav)\n",
        "ts = 120 # Number of testing files (.wav)\n",
        "\n",
        "X_train = np.zeros([tr,km,13])\n",
        "X_test = np.zeros([ts,km,13])\n",
        "\n",
        "tr_labels = np.zeros([tr],dtype=int)\n",
        "ts_act_labels = np.zeros([ts],dtype=int)\n",
        "ts_pred_labels = np.zeros([ts],dtype=int)\n",
        "dist_matrix = np.zeros([ts,tr])\n",
        "\n",
        "\n",
        "path = '/content/drive/My Drive/speech_utterances/training/' \n",
        "dirs = os.listdir(path)\n",
        "i = 0\n",
        "for fil in dirs:\n",
        "  (rate,sig) = wav.read(path+fil) # Reading the .wav file from above mentioned path for training data\n",
        "\n",
        "  tr_labels[i] = int(fil[10]) # Training label is present as 11th character or at 10th index in the name of training file\n",
        "\n",
        "  mfcc_feat = pd.DataFrame(mfcc(sig,rate)) # Extracting the MFCC features from the speech training file\n",
        "  # After extracing the mfcc_feat, we can see that it will be a feature matrix of dimension mostly as 88 rows x 13 columns, which can be interpreted as\n",
        "  # 88 feature vectors with every feature vector having dimension = 13. The number of rows/feature vectors may change from one .wav file to another but the\n",
        "  # columns will always be 13 which denotes the dimension of every mfcc feature vector.\n",
        "\n",
        "  clustering = KMeans(n_clusters=km) # Building a k-means clustering model, with k value set as km\n",
        "\n",
        "  clustering.fit(mfcc_feat) # Fitting the clustering model on all the 88 mfcc feature vectors with dimension as 13 (it could be 88 or more/less than that for some .wav files)\n",
        "\n",
        "  X_train[i] = clustering.cluster_centers_ # Storing the cluster centers as the representative of the .wav training file, in other words the whole .wav file\n",
        "  # which earlier was described as a feature matrix of 88 rows x 13 columns, can now be looked at as km number of data points in a 13 dimensional vector space.\n",
        "\n",
        "  i += 1\n",
        "\n",
        "# Repeating the exact same process for other .wav testing files-\n",
        "path = '/content/drive/My Drive/speech_utterances/test/' \n",
        "dirs = os.listdir(path)\n",
        "i = 0\n",
        "for fil in dirs:\n",
        "  ts_act_labels[i] = int(fil[10])\n",
        "  (rate,sig) = wav.read(path+fil)\n",
        "  mfcc_feat = pd.DataFrame(mfcc(sig,rate))\n",
        "  clustering = KMeans(n_clusters=km)\n",
        "  clustering.fit(mfcc_feat)\n",
        "  X_test[i] = clustering.cluster_centers_\n",
        "  i += 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bla9cVzxX0_Q"
      },
      "source": [
        "#### **4. Predicting the labels for test files-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQxYKmXgdna"
      },
      "source": [
        "for i in range(ts):\n",
        "  for j in range(tr):\n",
        "    dist_matrix[i][j] = dist(X_test[i],X_train[j]) # calculating the distance between the ith test speech file and jth training speech file\n",
        "\n",
        "for i in range(ts):\n",
        "  k_indices = np.argpartition(dist_matrix[i],kn) # Finding out the kn number of nearest neibours for every test .wav file\n",
        "  k_min_indices = k_indices[:kn]\n",
        "  mode_labels = tr_labels[k_min_indices]\n",
        "  mode,count = stats.mode(mode_labels)\n",
        "  ts_pred_labels[i] = int(mode)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0j4PwxUYLN3"
      },
      "source": [
        "#### **5. Result-**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbIL7o-hYK4T",
        "outputId": "b8cef3d0-4958-45ed-f3f2-134a959bbe07"
      },
      "source": [
        "arr = confusion_matrix(ts_act_labels, ts_pred_labels)\n",
        "print(\"Confusion Matrix:\\n\\n\",arr)\n",
        "print(\"\\n\")\n",
        "arr = confusion_matrix(ts_act_labels, ts_pred_labels)\n",
        "digit_ac = np.zeros(10) \n",
        "for i in range(10):\n",
        "  digit_ac[i] = np.round(arr[i][i]/sum(arr[i])*100,2)\n",
        "  print(\"Accuracy for digit class\",i,\":\",digit_ac[i],\"%\")\n",
        "\n",
        "ov_pc = round(sum(digit_ac)/len(digit_ac),2)\n",
        "print(\"\\n\")\n",
        "print(\"Overall Accuracy: \",ov_pc,\"%\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "\n",
            " [[ 1  1 10  0  0  0  0  0  0  0]\n",
            " [ 0 12  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 12  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  3  0  0  0  0  8  0]\n",
            " [ 0  0  3  0  9  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  6  1  0  4  0]\n",
            " [ 0  0  0  0  0  0 12  0  0  0]\n",
            " [ 1  1  3  0  1  0  1  3  2  0]\n",
            " [ 0  0  0  0  0  0  0  0 12  0]\n",
            " [ 0  2  2  0  0  0  0  0  1  7]]\n",
            "\n",
            "\n",
            "Accuracy for digit class 0 : 8.33 %\n",
            "Accuracy for digit class 1 : 100.0 %\n",
            "Accuracy for digit class 2 : 100.0 %\n",
            "Accuracy for digit class 3 : 25.0 %\n",
            "Accuracy for digit class 4 : 75.0 %\n",
            "Accuracy for digit class 5 : 50.0 %\n",
            "Accuracy for digit class 6 : 100.0 %\n",
            "Accuracy for digit class 7 : 25.0 %\n",
            "Accuracy for digit class 8 : 100.0 %\n",
            "Accuracy for digit class 9 : 58.33 %\n",
            "\n",
            "\n",
            "Overall Accuracy:  64.17 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEhft7EaYjcP"
      },
      "source": [
        "#### **6. Conclusion-**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCXNJhx8YodT"
      },
      "source": [
        "1. Digit recognition from speech using machine learning tools like K-Nearest neibours is very trivial. It can be seen from above that prediction accuracy for some digit classes is alright but for some digit classes it is simply unacceptable.\n",
        "\n",
        "2. Moving forward, a better technique would be to use more sophesticated statistical models like Hidden Markov Model (HMM) which is used to model problems that involve sequential information like speech. \n",
        "\n",
        "3. To get even better results, Deep learning based approach making use of CNN's could significantly improve the performance, provided we have a lot of data as opposed to just 300 .wav files we had for training in this project.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtGCmWMfdykf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}